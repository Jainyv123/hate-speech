{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKYAsdpapp8A"
      },
      "source": [
        "# Hate Speech Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL1co1l1pp8C",
        "outputId": "af100973-18c9-49bc-94d5-4d609d456bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install textstat\n",
        "import pandas as panda\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn\n",
        "from textstat.textstat import *\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bp_JYB-4qEcg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "LB_A7NuQpp8G",
        "outputId": "1eba78d4-5fb3-4a4c-d92f-585fca91ea85"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-43dde1db750f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpanda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Hate_speech/HateSpeechData.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Hate_speech/HateSpeechData.csv'"
          ]
        }
      ],
      "source": [
        "dataset = panda.read_csv(\"/content/Hate_speech/HateSpeechData.csv\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WKyRdEEpp8H"
      },
      "outputs": [],
      "source": [
        "# Adding text-length as a field in the dataset\n",
        "dataset['text length'] = dataset['tweet'].apply(len)\n",
        "print(dataset.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mEgy-RBpp8I"
      },
      "outputs": [],
      "source": [
        "#Basic visualization of data using histograms\n",
        "# FacetGrid- Multi-plot grid for plotting conditional relationships\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "graph = sns.FacetGrid(data=dataset, col='class')\n",
        "graph.map(plt.hist, 'text length', bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMIeQ4Z4pp8O"
      },
      "outputs": [],
      "source": [
        "# collecting only the tweets from the csv file into a variable name tweet\n",
        "tweet=dataset.tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1cF1NXNrZWu"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F79yIEGspp8P"
      },
      "source": [
        "## Preprocessing of the tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkFCRESWpp8Q"
      },
      "outputs": [],
      "source": [
        "## 1. Removal of punctuation and capitlization\n",
        "## 2. Tokenizing\n",
        "## 3. Removal of stopwords\n",
        "## 4. Stemming\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "#extending the stopwords to include other words used in twitter such as retweet(rt) etc.\n",
        "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
        "stopwords.extend(other_exclusions)\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(tweet):  \n",
        "    \n",
        "    # removal of extra spaces\n",
        "    regex_pat = re.compile(r'\\s+')\n",
        "    tweet_space = tweet.str.replace(regex_pat, ' ')\n",
        "\n",
        "    # removal of @name[mention]\n",
        "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
        "    tweet_name = tweet_space.str.replace(regex_pat, '')\n",
        "\n",
        "    # removal of links[https://abc.com]\n",
        "    giant_url_regex =  re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    tweets = tweet_name.str.replace(giant_url_regex, '')\n",
        "    \n",
        "    # removal of punctuations and numbers\n",
        "    punc_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \")\n",
        "    # remove whitespace with a single space\n",
        "    newtweet=punc_remove.str.replace(r'\\s+', ' ')\n",
        "    # remove leading and trailing whitespace\n",
        "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
        "    # replace normal numbers with numbr\n",
        "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
        "    # removal of capitalization\n",
        "    tweet_lower = newtweet.str.lower()\n",
        "    \n",
        "    # tokenizing\n",
        "    tokenized_tweet = tweet_lower.apply(lambda x: x.split())\n",
        "    \n",
        "    # removal of stopwords\n",
        "    tokenized_tweet=  tokenized_tweet.apply(lambda x: [item for item in x if item not in stopwords])\n",
        "    \n",
        "    # stemming of the tweets\n",
        "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
        "    \n",
        "    for i in range(len(tokenized_tweet)):\n",
        "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "        tweets_p= tokenized_tweet\n",
        "    \n",
        "    return tweets_p\n",
        "\n",
        "processed_tweets = preprocess(tweet)   \n",
        "\n",
        "dataset['processed_tweets'] = processed_tweets\n",
        "print(dataset[[\"tweet\",\"processed_tweets\"]].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVYM_xHqpp8S"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTNSLpoPpp8S"
      },
      "outputs": [],
      "source": [
        "# visualizing which of the word is most commonly used in the twitter dataset\n",
        "from wordcloud import WordCloud\n",
        "# imshow-Display data as an image\n",
        "# interpolation - https://matplotlib.org/3.2.1/gallery/images_contours_and_fields/interpolation_methods.html\n",
        "all_words = ' '.join([text for text in dataset['processed_tweets'] ])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "#random=0.30\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN0BVRoPpp8T"
      },
      "outputs": [],
      "source": [
        "# visualizing which of the word is most commonly used for hatred speech\n",
        "hatred_words = ' '.join([text for text in dataset['processed_tweets'][dataset['class'] == 0]])\n",
        "wordcloud = WordCloud(width=800, height=500,\n",
        "random_state=21, max_font_size=110).generate(hatred_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNL8Zd5pp8T"
      },
      "outputs": [],
      "source": [
        "# visualizing which of the word is most commonly used for offensive speech\n",
        "offensive_words = ' '.join([text for text in dataset['processed_tweets'][dataset['class'] == 1]])\n",
        "wordcloud = WordCloud(width=800, height=500,\n",
        "random_state=21, max_font_size=110).generate(offensive_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5tPM8Vdpp8U"
      },
      "outputs": [],
      "source": [
        "#TF-IDF Features-F1\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df=0.75, min_df=5, max_features=10000)\n",
        "\n",
        "# TF-IDF feature matrix\n",
        "tfidf = tfidf_vectorizer.fit_transform(dataset['processed_tweets'] )\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JkulvC0pp8V"
      },
      "source": [
        "### Running various model Using TFIDF without additional features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNCn_Wifpp8V"
      },
      "outputs": [],
      "source": [
        "# If you don't specify the random_state in the code, \n",
        "# then every time you run(execute) your code a new random value is generated \n",
        "# and the train and test datasets would have different values each time.\n",
        "X = tfidf\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.4)\n",
        "model = LogisticRegression().fit(X_train_tfidf,y_train)\n",
        "y_preds = model.predict(X_test_tfidf)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression, Accuracy Score:\" , acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_cGo7W4pp8V"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_preds = rf.predict(X_test_tfidf)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_12cIOHpp8W"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X.toarray(), y, random_state=42, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train_tfidf,y_train)\n",
        "y_preds = nb.predict(X_test_tfidf)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zne8nqt8pp8X"
      },
      "outputs": [],
      "source": [
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_tfidf,y_train)\n",
        "y_preds = support.predict(X_test_tfidf)\n",
        "acc3=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" , acc3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7xmyfcRpp8X"
      },
      "outputs": [],
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision for F1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLoEb3ZPr51w"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zTOCDEypp8Y"
      },
      "source": [
        "### Sentiment Analysis, using polarity scores as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOpJ3Uhipp8Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "sentiment_analyzer = VS()\n",
        "def count_tags(tweet_c):  \n",
        "    \n",
        "    space_pattern = '\\s+'\n",
        "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    mention_regex = '@[\\w\\-]+'\n",
        "    hashtag_regex = '#[\\w\\-]+'\n",
        "    parsed_text = re.sub(space_pattern, ' ', tweet_c)\n",
        "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
        "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
        "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
        "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
        "\n",
        "def sentiment_analysis(tweet):   \n",
        "    sentiment = sentiment_analyzer.polarity_scores(tweet)    \n",
        "    twitter_objs = count_tags(tweet)\n",
        "    features = [sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],twitter_objs[0], twitter_objs[1],\n",
        "                twitter_objs[2]]\n",
        "    #features = pandas.DataFrame(features)\n",
        "    return features\n",
        "\n",
        "def sentiment_analysis_array(tweets):\n",
        "    features=[]\n",
        "    for t in tweets:\n",
        "        features.append(sentiment_analysis(t))\n",
        "    return np.array(features)\n",
        "\n",
        "final_features = sentiment_analysis_array(tweet)\n",
        "#final_features\n",
        "\n",
        "new_features = panda.DataFrame({'Neg':final_features[:,0],'Pos':final_features[:,1],'Neu':final_features[:,2],'Compound':final_features[:,3],\n",
        "                            'url_tag':final_features[:,4],'mention_tag':final_features[:,5],'hash_tag':final_features[:,6]})\n",
        "new_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0xzGNuEpp8Z"
      },
      "outputs": [],
      "source": [
        "# F2-Conctaenation of tf-idf scores and sentiment scores\n",
        "tfidf_a = tfidf.toarray()\n",
        "modelling_features = np.concatenate([tfidf_a,final_features],axis=1)\n",
        "modelling_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpO0Dj2hpp8Z"
      },
      "source": [
        "### Running various model Using TFIDF and additional features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Rwqla1pp8Z"
      },
      "outputs": [],
      "source": [
        "# Running the model Using TFIDF with some features from sentiment analysis\n",
        "\n",
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_bow,y_train)\n",
        "y_preds = model.predict(X_test_bow)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression,Accuracy Score:\" , acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2H2n2gUpp8a"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_preds = rf.predict(X_test_bow)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdyzx0lopp8a"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train_bow,y_train)\n",
        "y_preds = nb.predict(X_test_bow)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6gmxON6pp8b"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_bow,y_train)\n",
        "y_preds = support.predict(X_test_bow)\n",
        "acc3=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" , acc3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alZJtWmBpp8b"
      },
      "outputs": [],
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision for F2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLZu6uFGpp8c"
      },
      "outputs": [],
      "source": [
        "# create doc2vec vector columns\n",
        "# Initialize and train the model\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "#The input for a Doc2Vec model should be a list of TaggedDocument(['list','of','word'], [TAG_001]). \n",
        "#A good practice is using the indexes of sentences as the tags.\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dataset[\"processed_tweets\"].apply(lambda x: x.split(\" \")))]\n",
        "\n",
        "# train a Doc2Vec model with our text data\n",
        "# window- The maximum distance between the current and predicted word within a sentence.\n",
        "# mincount-Ignores all words with total frequency lower than this.\n",
        "# workers -Use these many worker threads to train the model\n",
        "#  Training Model - distributed bag of words (PV-DBOW) is employed.\n",
        "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
        "\n",
        "#infer_vector - Infer a vector for given post-bulk training document.\n",
        "# Syntax- infer_vector(doc_words, alpha=None, min_alpha=None, epochs=None, steps=None)\n",
        "# doc_words-A document for which the vector representation will be inferred.\n",
        "\n",
        "# transform each document into a vector data\n",
        "doc2vec_df = dataset[\"processed_tweets\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(panda.Series)\n",
        "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
        "doc2vec_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-EOc16cpp8c"
      },
      "outputs": [],
      "source": [
        "# conctaenation of tf-idf scores, sentiment scores and doc2vec columns\n",
        "modelling_features = np.concatenate([tfidf_a,final_features,doc2vec_df],axis=1)\n",
        "modelling_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jM-flE6pp8d"
      },
      "source": [
        "### Running the models Using TFIDF with additional features from sentiment analysis and doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn3WXzaDpp8d"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_bow,y_train)\n",
        "y_preds = model.predict(X_test_bow)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression, Accuracy Score:\" , acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKL9n8Vwpp8d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_preds = rf.predict(X_test_bow)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTs_Jq3app8e"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train,y_train)\n",
        "y_preds = nb.predict(X_test)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJNWDUaWpp8e"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_bow,y_train)\n",
        "y_preds = support.predict(X_test_bow)\n",
        "acc3=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" , acc3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQKR4IZypp8f"
      },
      "outputs": [],
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skt1ySglpp8f"
      },
      "outputs": [],
      "source": [
        "#Using TFIDF with sentiment scores,doc2vec and enhanced features\n",
        "def additional_features(tweet): \n",
        "    \n",
        "    syllables = textstat.syllable_count(tweet)\n",
        "    num_chars = sum(len(w) for w in tweet)\n",
        "    num_chars_total = len(tweet)\n",
        "    num_words = len(tweet.split())\n",
        "    # avg_syl = total syllables/ total words\n",
        "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
        "    num_unique_terms = len(set(tweet.split()))\n",
        "    \n",
        "    #  Flesch–Kincaid readability tests are readability tests \n",
        "    #  designed to indicate how difficult a passage in English is to understand. \n",
        "    # There are two tests, the Flesch Reading Ease, and the Flesch–Kincaid Grade \n",
        "    # A text with a comparatively high score on FRE test should have a lower score on the FKRA test.\n",
        "    # Reference - https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
        "    \n",
        "    ###Modified FK grade, where avg words per sentence is : just num words/1\n",
        "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
        "    ##Modified FRE score, where sentence fixed to 1\n",
        "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
        "    \n",
        "    add_features=[FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_words,\n",
        "                num_unique_terms]\n",
        "    return add_features\n",
        "\n",
        "def get_additonal_feature_array(tweets):\n",
        "    features=[]\n",
        "    for t in tweets:\n",
        "        features.append(additional_features(t))\n",
        "    return np.array(features)\n",
        "\n",
        "fFeatures = get_additonal_feature_array(processed_tweets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKXzveh0pp8g"
      },
      "outputs": [],
      "source": [
        "tfidf_a = tfidf.toarray()\n",
        "modelling_features_enhanced = np.concatenate([tfidf_a,final_features,doc2vec_df,fFeatures],axis=1)\n",
        "modelling_features_enhanced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6dR1n--pp8g"
      },
      "source": [
        "### Running the models Using TFIDF with sentiment scores,doc2vec and enhanced features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AemiXsukpp8h"
      },
      "outputs": [],
      "source": [
        "# Running the model Using TFIDF with enhanced features\n",
        "\n",
        "X = panda.DataFrame(modelling_features_enhanced)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_features, X_test_features, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_features,y_train)\n",
        "y_preds = model.predict(X_test_features)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression, Accuracy Score:\" , acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zULBnIiJpp8h"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix for TFIDF with additional features \n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
        "matrix_proportions = np.zeros((3,3))\n",
        "for i in range(0,3):\n",
        "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
        "names=['Hate','Offensive','Neither']\n",
        "confusion_df = panda.DataFrame(matrix_proportions, index=names,columns=names)\n",
        "plt.figure(figsize=(5,5))\n",
        "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='YlGnBu',cbar=False, square=True,fmt='.2f')\n",
        "plt.ylabel(r'True Value',fontsize=14)\n",
        "plt.xlabel(r'Predicted Value',fontsize=14)\n",
        "plt.tick_params(labelsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cCGox6ppp8h"
      },
      "outputs": [],
      "source": [
        "# From the confusion matrix its clear that the model misclassifies 78% of the hate data as offensive data. This explains the reduction in class-0\n",
        "# bar on the histogram for the predicted class and increase of bar for class-1 (offensive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-0_dT7Tpp8h"
      },
      "outputs": [],
      "source": [
        "testing_index=list(X_test_features.index[0:10])\n",
        "#print(testing_index)\n",
        "print(\"Predicted Class:\",y_preds[0:10])\n",
        "print(\"Actual Class:\",y_test.tolist()[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A46umPN5pp8i"
      },
      "outputs": [],
      "source": [
        "# Histogram presenting the count of different classes- Actual\n",
        "ax=y_test.hist()\n",
        "ax.set_xlabel(\"Class\", labelpad=20, weight='bold', size=12)\n",
        "ax.set_ylabel(\"Count\", labelpad=20, weight='bold', size=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvTzu75Qpp8i"
      },
      "outputs": [],
      "source": [
        "# Histogram presenting the count of different classes- Predicted\n",
        "ax=panda.Series(y_preds).hist()\n",
        "ax.set_xlabel(\"Class\", labelpad=20, weight='bold', size=12)\n",
        "ax.set_ylabel(\"Count\", labelpad=20, weight='bold', size=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiCG71ALpp8j"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features_enhanced)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_features, X_test_features, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_features,y_train)\n",
        "y_preds = rf.predict(X_test_features)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrYZ9GHIpp8k"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features_enhanced)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_features, X_test_features, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train_features,y_train)\n",
        "y_preds = nb.predict(X_test_features)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBNC25lBpp8k"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix for TFIDF with additional features \n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
        "matrix_proportions = np.zeros((3,3))\n",
        "for i in range(0,3):\n",
        "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
        "names=['Hate','Offensive','Neither']\n",
        "confusion_df = panda.DataFrame(matrix_proportions, index=names,columns=names)\n",
        "plt.figure(figsize=(5,5))\n",
        "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='YlGnBu',cbar=False, square=True,fmt='.2f')\n",
        "plt.ylabel(r'True Value',fontsize=14)\n",
        "plt.xlabel(r'Predicted Value',fontsize=14)\n",
        "plt.tick_params(labelsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXo4K0eWpp8l"
      },
      "outputs": [],
      "source": [
        "X = panda.DataFrame(modelling_features_enhanced)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_features, X_test_features, y_train, y_test_helo = train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_features,y_train)\n",
        "y_preds = support.predict(X_test_features)\n",
        "acc3=accuracy_score(y_test_helo,y_preds)\n",
        "report = classification_report( y_test_helo, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" ,acc3 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7X6FI07pp8l"
      },
      "outputs": [],
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}